{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import statsmodels.formula.api as smf \n",
    "import statsmodels.api as sm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Rong/Desktop'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.017612</td>\n",
       "      <td>14.053064</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.395634</td>\n",
       "      <td>4.662541</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.752157</td>\n",
       "      <td>6.538620</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.322371</td>\n",
       "      <td>7.152853</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.423363</td>\n",
       "      <td>11.054677</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0          1  2\n",
       "0 -0.017612  14.053064  0\n",
       "1 -1.395634   4.662541  1\n",
       "2 -0.752157   6.538620  0\n",
       "3 -1.322371   7.152853  0\n",
       "4  0.423363  11.054677  0"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testSet = pd.read_csv(\"testSet.txt\", sep= \"\\\\s+\", header = None)\n",
    "##dataPlot = sns.lmplot('x', 'y', 'type', data=testData, ci =None)\n",
    "testSet.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class logistic_regression(classifier):\n",
    "\n",
    "    def __init__(self, cycles):\n",
    "        self.alpha = 0.001\n",
    "        self.maxcycles = cycles\n",
    "        self.weights = None  # Placeholder for later...\n",
    "\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1.0 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "    def fit(self, Xin, Yin):\n",
    "        print('Logistic Regression classifier - fit')\n",
    "\n",
    "        X = np.mat(Xin)\n",
    "        Y = np.mat(Yin).transpose()\n",
    "        m, n = X.shape\n",
    "        self.weights = np.ones((n, 1))\n",
    "        for k in range(self.maxcycles):\n",
    "            h = self.sigmoid(X * self.weights)\n",
    "            error = (Y - h)\n",
    "            self.weights = self.weights + self.alpha * X.transpose() * error\n",
    "        return self.weights\n",
    " \n",
    "\n",
    "    def predict(self, X):\n",
    "        hypotheses = []\n",
    "        for x in X:\n",
    "            prob = self.sigmoid(sum(x*self.weights))\n",
    "            if prob > 0.5:\n",
    "                hypotheses.append(1)\n",
    "            else:\n",
    "                hypotheses.append(0)\n",
    "        return hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression classifier - fit\n",
      "Weights: [[ 9.35184677]\n",
      " [ 0.87401362]\n",
      " [-1.28891422]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xt0nFd57/Hvo4tvmrHj2JLjixIT\nS0lIQ5wSYbdN4SQFQmIuoWdBV3IOkLYUJyxI27UOK9wW0ELbczCctucE2lyaHCgE6FkFQg4YSArt\nClBwbKc2CSTBcm6ynVhyHMu6+CbpOX/MSBqNRtK80sy8+331+6ylpZlXr0bPaKT3mb33s/c2d0dE\nRKRcdXEHICIiyaLEISIikShxiIhIJEocIiISiRKHiIhEosQhIiKRKHGIiEgkShwiIhKJEoeIiETS\nEHcA1bBy5Upfv3593GGIiCTG7t27j7h7cznnpjJxrF+/nl27dsUdhohIYpjZs+Weq64qERGJRIlD\nREQiUeIQEZFIqp44zOweM+s2s8cKjv2ZmR00sz35jy1TfO81ZvakmXWa2YeqHauIiMysFi2OLwDX\nlDj+N+5+Wf5je/EXzawe+DxwLXAxcIOZXVzVSEVEZEZVTxzu/hBwdBbfugnodPen3P008DXguooG\nJyIikcU5xvF+M/t5vitreYmvrwW6Cu4fyB8TEZEYxZU4/h7YAFwGPA/8zxLnWIljU+5za2ZbzWyX\nme3q6empTJQiCdbV28Ut229h012buGX7LXT1ds38TSJliGUCoLsfHr1tZncB3y5x2gGgteD+OuDQ\nNI95J3AnQEdHhzZSl3mtq7eLjbdvpP90P2dGzrDnhT3c++i97L15L63LWmd+AJFpxNLiMLPVBXd/\nF3isxGk7gXYze5mZLQCuB+6vRXwiSbftJ9vGkgbAmZEz9J/uZ9tPtsUcmaRB1VscZvZV4EpgpZkd\nAD4BXGlml5HrenoGuCl/7hrgH9x9i7sPmdn7ge8D9cA97v6LascrkgY7Du4YSxqjzoyc4eGDD8cU\nkaRJ1ROHu99Q4vDdU5x7CNhScH87MKlUV0Smt3ntZva8sGdC8misa2TT2k0xRiVpoZnjIil06xW3\nklmQobGuEcgljcyCDLdecWvMkUkaKHGIpFDrslb23ryXmy6/iU1rNnHT5TdpYFwqJpXLqoukRVdv\nF9t+so0dB3ewee1mbr3i1rIv/q3LWrlty21VjlDmIyUOkUCppFZCpa4qkUCppFZCpcQhEiiV1Eqo\nlDhEAlK4TMjJoZM02MTe5FBKarWcyfymMQ6RQBSPaTTUNTDswzRYA0M+FExJrcZeRC0OkUAUj2kM\njQzRUNfAy5tfHlRJrcZeRC0OkUBMNaaxuGExO96zI6aoJtPYi6jFIRKIzWs3j830HhXKmEahpMQp\n1aPEIRKIpCwTkpQ4pXqUOEQCkZRlQmoRp6q2wmbu6dvzqKOjw3ft2hV3GCIyC8VVW6MtmhCTaJqY\n2W537yjnXLU4RCQoqtoKnxKHiARFVVvhU+IQkaCoait8ShwiUlJcA9TVrNrSoHtlaHBcRCaJe4B6\ndB+SHz33I0Z8hDqr49XnvjrSfiSlHlOD7lMLanDczO4xs24ze6zg2GfM7Akz+7mZfdPMzprie58x\ns0fNbI+ZKROI1EjcA9Sty1q59Ypbea73OZ448gR7D+/ljt13sPH2jbNuJcT9nNKkFl1VXwCuKTr2\nIHCJu18K/Ar48DTff5W7X1ZuJhSRiWbTPRPCAHWlL/QhPKe0qHricPeHgKNFxx5w96H83Z8B66od\nh8h8NNo9c8fuO9h5aGfZ79pDGKCu9IU+hOeUFiEMjv8h8N0pvubAA2a228y2TvcgZrbVzHaZ2a6e\nnp6KBymSRB/74cc4dvJY5HftISwrUukLfQjPKS1iTRxm9lFgCLh3ilOucPdXAtcC7zOz10z1WO5+\np7t3uHtHc3NzFaKValPFS2V19Xbx5Ue/jDOxAKacd+0hLH9S6Qt9CM8pLWpSVWVm64Fvu/slBcdu\nBG4GXuvug2U8xp8B/e7+2ZnOVVVV8qjipfJu2X4Lf7fz7xhhZMJxw3jXpe8iuzDLjoM72Lx285yq\nlapptLrq4YMPs2ntpmDjTIMoVVWx7MdhZtcAHwT+01RJw8yagDp378vfvhr4ZA3DlBqabiD0ti23\nxRxdMu04uGNS0oBc4rjvyfsYPDMY/A5+rcta9foHqBbluF8FfgpcaGYHzOzdwOeALPBgvtT29vy5\na8xse/5bVwE/NrO9wMPAd9z9e9WOV+KhipfKKzVGUEcd7Svax5IGqCxVoqt6i8Pdbyhx+O4pzj0E\nbMnffgrYWMXQJCCb125mzwt7JiSPkCteRrtQQu7qufWKW7n30Xsndf8talikJC1zEkJVlUiiKl5m\nW+Jaa1MNBr/63FerLFXmREuOSDCSMhB6y/ZbuGP3HZNaRzddflMi+uNDKkQobrm949J38OWffzno\nllxaRRkcV+KQeaert4uP/fBjfLfzu2Bwbdu1fOqqT5V9gdp01yZ2Hto5+fiaTex4z45Kh1sVISTp\n4gTWYA0M+zD1dfUMjQypsq7Ggq+qEolLV28Xr/j7V9B7qnfs2Bf3fpH7nriPR9/7aFkXqKSNx5QS\nQrVScSXdUH4xiaGR3GdV1oVLYxySCuVOHtz2k20cP3V80vG+U31lVxUlaTwmZKUq6Ypp0D5ManFI\n4hV3eUw3L2HHwR2TZlIDjDBS9gVqdNA57q6epCvVciuWtJbcfKEWhyRelFVUN6/djGGTjtdRF+kC\nNdrVs+M9O7hty21KGrNQ3HJrsAYMo6Eu935WLblwKXFI4kWZPHjrFbeydOHSScezC7Pz4gIV0npg\nxeXCN3fczE/f/VNuvvxmrSUVOHVVSeJFGaxuXdbKo+99dNqqqpAn980ltuIuvf94/j+465G7uGjl\nRXPeXW+2Sg3Sb163uaYxSHQqx5XEq+S8hJDmOFQ6tlLzT0aF9DwlHkFtHStSbZVcLjvk7UXnGtt0\nVUwhPU8Jn7qqJBUqNS+hGostVqrra66xzVTFNNNjhdyFJ7WlxCFSoNKT+6KUClc7tuJFD4tN91iV\nfB6SfOqqkkSrdJVQpSf3VbLra66xFXbpbVy1kYX1C8sufQ25C09qTy0OSaxqvAuu9OS+uXQvleoa\nmmtshV16Udar0n4pUkiJQxKrWrsGTjdeErWf/+Lmi9l9aPeEnfjK6V6aLilWat2mKONCaVifSypH\nXVWSWLV+Fxx1H46u3i7ue+K+Sdu3LmlcMmP3UmhdQ2lZnyukCZBJpsQhiVVqa9RqvguOejHf9pNt\nDJ4ZnHDMMN564Vtn7F4KrWuokiXPcUnKBlxJUJPEYWb3mFm3mT1WcOxsM3vQzPblPy+f4ntvzJ+z\nz8xurEW8kgy1fhcc9WJe6nzHefzI4zP+rFonxXIkfX2u0FpxSVarFscXgGuKjn0I+IG7twM/yN+f\nwMzOBj4BbAY2AZ+YKsHI/FPrd8FRL+ZzufinpWsoJKG14pKsJonD3R8CjhYdvg74Yv72F4G3lvjW\nNwAPuvtRd38JeJDJCUjmsVq+C456MZ/Lxb9WSXE+9fmH2IpLqpqtVWVm64Fvu/sl+fvH3P2sgq+/\n5O7Li77nA8Aid/+L/P2PASfc/bPT/SytVSXVEnXL1RC2aJ1KyOtyVcN8e75RpWnr2MkbJ1BiFx7A\nzLYCWwHOPffcasYk81jUpU1qsUXrbJcCqVY5c6i0AVflxJk4DpvZand/3sxWA90lzjkAXFlwfx3w\nb6UezN3vBO6EXIujsqGKhGkukyBD6PMvJ+lVco2sEPZaT4M4E8f9wI3A/8h//laJc74P/FXBgPjV\nwIdrE55EoQXw4jFVq+GNX3kjixoWTftaTLXo4YmhE3T1dlX99Ssn6WmNrDDVqhz3q8BPgQvN7ICZ\nvZtcwni9me0DXp+/j5l1mNk/ALj7UeBTwM78xyfzxyQgqo+Pz1Sthke7H53xtRgdvB9dr2rU4z2P\n1+T1K6c8ViW0YapVVdUN7r7a3RvdfZ273+3uL7r7a929Pf/5aP7cXe7+RwXfe4+7t+U//k8t4pVo\n9M8dn1KVQoWmei1GW4ity1pZumDiVrpDPlST16+crrKHnnso9u40mSz0wXFJgBD6yuermZZKh8mv\nRXH3TznfUw0zrX/V1dvFk0eenPR9DdagEtqYackRmTPVx8eneL7HK1peQYNNfD9Y/FoUtxBLqcXr\nN9M8l20/2cawD0/6vvq6ek2EjJkSh8zZVBeAd1z6jkRPLgthclw5MRROgvzOf/kO2YXZaScdTreF\n7FTfUw0zTXLccXAHQyNDk77vopUXzcuB8ZERp+voIP/6ZDd3PfQUDz8d33BvzSYA1pImANZe8US3\nd1z6Dq6999rETrYKYbLYbGOYadLhLdtv4Y7dd0zqIrpo5UUsblgczPyGqeK86fKbUl1SOzQ8wrNH\nB+ns7h/72Nfdx/7uAU6cGW+Bvf+qNj7whgsr9nOjTABU4pCqSPo/fQjxVyuGEJJiOZIS52ydGhrm\n6SMD7Ds8MUE8fWSAM8Pj1+U1yxbRtipLW3OG9lUZ2loytDVnWN60oKLxpGnmuCRU0gfMQ4i/WjEk\nZQZ1UuKcycCpIfb39OcSRP7z/p5+nn1xgJF8fqgzOPfsJbS1ZPmdi1bR3pJLEBtaMmQWhneZDi8i\nSYWk7xgXQvzlxjCbyZdJmUGdlDgBjg2ezrca+sc+7+/u5+CxE2PnNNYb61c08fLVWd586WraVmVp\nb8nwspVNLGqsjzH6aNRVJVWR9G6GEOIvJ4YQ4pxP3J2evlNFCaKPzu4BjvSfGjtvUWMdG5ozYy2H\n3EeW81YsobE+zJokjXEocQQh5JVhyxFC/LMd6E7KWFKoRkacQ70nxscexrqZ+jh+crzSK7uwgQ0t\nuQQxPv6QZd3yxdTVlVqjNVxKHEocMk9sumsTOw/tnHx8zSZ2vGdHDBEly9DwCF0vnWDf4T46e/rp\nzCeIzu5+Bk+PVzCtaFpQ0HLI0N6SpX1VhpbsQsxiThBLl0Jf3+Tj2SwcP172w2hwXGSeqMhYTIUu\nPCE7NTTMM0cG891K+W6mw/08fWSA08MjY+eds3QRbS0Zfq+jNdeCaM7QvirL2RWuYKqoUq/ddMcr\nQIlDJMGKlxyZ1eS9GC481TJ4eoj93QMTEsT+7n6ePTrIcL6EyQxaly+hrSXDlRc2T2hJZBdNve6X\njFPiEEmwtJSsRtV74kx+/KFvQplrYQVTQ52xfmUTF6zKsuUVq8fGIDY0ZxJVwRQijXGIVEGi9ieZ\nro8+xuuDu3Ok/3R+1vR4FVNndz/dfeMVTAsb8hVM+a6ltvxA9XkrmoKtYKqoCr1+GuMQiZE2H4rG\n3Xm+9yT7unNVS6OT5fZ199N7YnzsJpOvYHrNBc35Aepckli3fAn1CatgSjolDpEKm297eZdreMR5\nrmANptGWRGd3PwMFFUzLlzTS3pLljZeunrDMxjlLF8VfwRSibHbq4oYqUeIQqbAQliuJpMIXntND\nIzzz4sDY/IfRgeqnjgxwemi8gmnV0oW0t2R5e0crG1oyXJBvQazILJztM5mfYqh8U+IQqbAQliuJ\nZJYXnhOnh9nfUzh7Ote99OyLEyuY1i1fTHtLNtfF1JyhLd+CWFqrCqZ5UG5ca7ElDjO7EPingkPn\nAx93978tOOdK4FvA0/lD33D3T9YsSJFZqEiJbECOn8xXMBXMnt6XX4NpdOy1vs44b8US2lsybLlk\nda60dckA//yrz7P7hZ/S1LKZd8ZVIJCicuNQBFFVZWb1wEFgs7s/W3D8SuAD7v6mKI+nqiqJWwjL\nlUT1Yv+pCZVLoy2Jw8fHK5gW5CuYRpf2bl+VG6Q+b0UTCxrGK5iCWkMr0Kqx0CSxquq1wP7CpCGS\nZKGu6uruvHD85NgeEPvycyE6u/t5aXC8a61pQT1tLRl+u218gtwFq8qvYFKBQLqFkjiuB746xdd+\n08z2AofItT5+UbuwRJJpeMQ5+NKJCWMPo7Oo+0+NL9J31pJG2lsyXHPJObS1ZMeSxJplc6tgSlyB\ngEQSe+IwswXAW4APl/jyI8B57t5vZluA+4D2KR5nK7AV4Nxzz61StCJhOTM8wrMvDozNexhNEk/1\n9HOqoIKpJbuQtpYM//mVa2kv2E1uRdOCqpS4Jq5AQCKJfYzDzK4D3ufuV5dx7jNAh7sfme48jXGk\nV6JmZFfQaAXTWBVTfqD6mSMDDI2M/w+vW754wuS40X0gli2u7RpMQY1xqKqqLEkb47iBKbqpzOwc\n4LC7u5ltAuqAF2sZnIRjPszI7stXMI12K422IrpeGpxYwXT2Eja0ZLj64lX5Aeos5zc3sWTBFP/S\nNb54BrWGlpJDxcWaOMxsCfB64KaCYzcDuPvtwNuA95rZEHACuN7jbiJJbNI04Hp04PTYHhCje1Dv\nO9zPC8dPjp2zoL6O85ubuHTdslwXU34PiPNWLGFhQ8RF+ipdklpGIgq1QEDmLtbE4e6DwIqiY7cX\n3P4c8Llax5UaKWuiJ23A1d05fPzUWFlrYanr0YHTY+ctyVcw/daGFbnJcfk9IFqXL6aheJG+UF5T\nzY2Y10LoqpJqSdk/d6gDriMjzsFjBRVMh8e7mvoKKpiWLW6kLd+9NLaT3Kosq5cuKn+b0ZS9ppJM\nShySGHHPyM5VMA2OzXsYbUHs7+nn5JnxCqbm7ELamjP87ivXTthqdGWmOhVMIrWmxCGJUasB15Nn\nhnn6yEB+e9HxcYhnXhzgzPD4ENvas3IVTL9x/ooJVUxnLQl4m1GRClDikESp5IBr/6mhSUt87+vu\np+voIOMVriM0LT7Br69bzesuPp/2lvEKpqaFCfr3iWHpbSkSyvhUBSToL19kdl4aOD3WaihcyfX5\n3vEKpsZ64/yVGS5Zs4yrLsrwd3s+Tv/IPk74czTWwfNHMvz3t+2lddm6GJ/JHFT6wqREFF2KxqeU\nONJsHv1zuzvdfacmtCBGbx/pH69gWtxYz4aWJn7j/BUFE+QynHf2krEKplu238IxfsAZzoDBmRHC\nKfsN5TVN2DtkqSwljjRL4T/3aAVTcYLY191P38nxCqbsogbaWzL8zkUttLdkx8pc1561eMYKpqDL\nflP4mkryKHFIkIaGR3j26GDB5LjcIPX+7gFOnBnfZnRlZgFtLRmuu2zN2PyH9pYMzdmFs65gCqLs\nNw394Wl4DlJS7GtVVYPWqkqOU0P5CqbD/TzSdZDvPbGX7t56RoZW4j4++W3NskW0FSzON7ofxPKm\nylcwBbHOUhr2kEjDc6ikwH8fSVurSuaBgQkVTKMzqPt4rqCCyRlh2JzT9jTDDT+mobGbL739s/zW\n+RvI1LCCKah1lsqld/fhC2V8qgKm/W80s6VAs7vvLzp+qbv/vKqRSSL1Dp4puQfEwWMnxs5prDde\ntrKJi9cs5S0b17ChJcPXf/V5vvbE/+aMD4yfZ438v6fXc/XLaz8gnbh1llJUsZNaKUrgUyYOM/s9\n4G+BbjNrBH7f3Xfmv/wF4JXVD09C5O709J8q2IN6vCVxpH98m9FFjbltRl+1fjk3tLSObRR03ool\nNBatwfSXO/9lQtKAgAakS9E7/OktXRp3BFJF07U4PgJc7u7P55c0/5KZfcTdvwFo3YR5YGTEOdQ7\nXsE01oo43MfxwgqmhQ20rcpw1YXNY+MP7S3ZsiqYRgUxIB2F3uFPT7+HVJsucdS7+/MA7v6wmV0F\nfNvM1gHxj+RIxQwNj/Dc0cFccujpH2tJdHb3M3h6vIJpRVOugunNG9fkl9jILfPdMocKplFxr0MV\nnBT1h0+Shucwz02XOPrMbMPo+Ea+5XElue1bf60WwUllnRoa5pkjgxPGIDoP9/P0kQFOD48v0nfO\n0kW0tWT4vY7WsU2C2loynF2FCqZRiRyQrqY0d3fV6rmpO7FqpizHNbONwCDQ6O6/LDjeSG5DpS/V\nJsTo5ns57uDpIfZ3D9DZ0zc2/tDZ3c+zRwcZzpcwmUHr8iVFW4zmPrKLarvNaCKFVloZ2kUyhN9P\nCDEkSEXKcd19b/7BHjOzLwHbgEX5zx1AsIljvugdPENnz/geEKMD1YUVTA11xvqVTVywKssbL11N\nW0uGDc25BLGoMeIuchIuvYOWGiqnOH4z8Gng34EscC9wRTWDknHuzpH+02PzHgrnQXT3jVcwLWzI\nVTBdft5yrn9Va36ToAznnt3Egoa6aX6CzEqaxyAqQb+fVCsncZwht9/3YnItjqfdfWT6b5Go3J3n\ne0+OVS2N7kHd2dPPscHxSqPMwgY2tGR4zQXNY7OnL1iVZe3yxdSXu4uczJ3e4U9Pv59UKydx7AS+\nBbyK3P7gd5jZ29z9bZUIwMyeAfqAYWCouI/NcuU6/wvYQm7M5ffd/ZFK/OwQ7HzmKH/x7V/S2d3P\nQEEF0/IljbS3ZNnyitUTxiHOWbpIu8jJ/FWLsZzQxosCVE7ieLe7j440vwBcZ2bvrHAcV7n7kSm+\ndi3Qnv/YDPx9/nMqNC1oILuokbd35LuX8gliRWZh3KGJVM9sL85R5s/MtrtMc3RmNGPiKEgahcdq\nOTB+HfCPniv/+pmZnWVmq0fnmCTdxWuW8uU/Sk0eFClPLS7Oah1UTQijpg48YGa7zWxria+vBboK\n7h/IH5vAzLaa2S4z29XT01OlUEUiWLo0VxJa/KHlOCThQkgcV7j7K8l1Sb3PzF5T9PVSHfqTirDd\n/U5373D3jubm5mrEKXFI8sVXXR6SUrEnDnc/lP/cDXwTKF6c6ABQOH14HXCoNtFJ7HTxFQlOrInD\nzJrMLDt6G7gaeKzotPuBd1nObwC9aRnfEJGIphrYruT8kFr8jISLeyOnVcA38+WlDcBX3P17ZnYz\ngLvfDmwnV4rbSa4c9w9iilXSSuWXtTfbiqdavB56zWcUa+Jw96eAjSWO315w24H31TIumWfUHVZ7\nujgnWuxjHCKppS4PSam4u6pEppfkNY/0rlpSSi0OCdvx47klsIs/Qr8oJ7mMWGQGShwi1aBxE0kx\nJQ4REYlEiUNERCJR4hARkUiUOEREJBIlDpFqiHsOh6q6pIo0j0OkGuIuF1ZVl1SRWhwilWod6F2+\nzBNKHCKVmmSod/nlCTHBhhhTwJQ4RKS2QkywIcYUMCUOERGJRIlDJI3iruqSVFPiEIlbNfrXk7o4\npCSCEodIpcz2Xb761yVhlDikNFWZRFeNd/kh/v7n+rcRYjdaiDEFLLbEYWatZvavZva4mf3CzP6k\nxDlXmlmvme3Jf3w8jljnJb0LDlOtfv/TJYe5/m2E2I0WYkwBi3Pm+BDw39z9ETPLArvN7EF3/2XR\neT9y9zfFEJ/I/KU3DjKN2Foc7v68uz+Sv90HPA6sjSseEREpTxBjHGa2Hvh1YEeJL/+mme01s++a\n2a/VNDCRWlA/uiRM7InDzDLA14E/dffiDsVHgPPcfSNwG3DfNI+z1cx2mdmunp6e6gUsUmml+tfn\nKxVlJEKsicPMGskljXvd/RvFX3f34+7en7+9HWg0s5WlHsvd73T3DnfvaG5urmrc84KqTOIV8u+/\nmrFpbCURYhscNzMD7gYed/e/nuKcc4DD7u5mtolconuxhmHOX6omiVfcv/9stvTFOpuNPzaJXZxV\nVVcA7wQeNbM9+WMfAc4FcPfbgbcB7zWzIeAEcL37fG7Hi1TIVGW1o4lByUGmEVvicPcfAzbDOZ8D\nPlebiETmEXUJyRzEPjguIiLJosQh6aPKnOQKuShAxihxSPqoG6b2KpWstfRHIihxiMjcKVnPK0oc\nIvORuoRkDuIsxxWRuKjrR+ZALQ6R6WigXWQSJQ5Jn0p2w6jvXmQSdVVJ+qgbpvamW6JEUkctDpGk\nCbH7TGW084oSh0jSqPtMYqbEISIikShxiExH8x1EJlHiEJmO+u4rK8TxGYlMiUOSIW0XnLQ9n3Jp\nfCYVlDgkGdJ2wZnL81H3mcRM8zhEkkbdZBIztThkovnahSIiZYs1cZjZNWb2pJl1mtmHSnx9oZn9\nU/7rO8xsfe2jnGfS1iWUJkrqEojYEoeZ1QOfB64FLgZuMLOLi057N/CSu7cBfwN8urZRSsXp4jd7\naUjqGp9JhThbHJuATnd/yt1PA18Dris65zrgi/nb/wy81syshjFKpc324pe2C07ank+5VN6cCnEO\njq8FugruHwA2T3WOuw+ZWS+wAjhSkwglHGm7sKTt+ci8EmeLo1TLwWdxTu5Es61mtsvMdvX09Mw5\nOBERKS3OxHEAaC24vw44NNU5ZtYALAOOlnowd7/T3TvcvaO5ubkK4c4T87ULRUTKFmfi2Am0m9nL\nzGwBcD1wf9E59wM35m+/Dfihu5dscUiFqA86XErqEojYxjjyYxbvB74P1AP3uPsvzOyTwC53vx+4\nG/iSmXWSa2lcH1e8MkdLl04/AK6L38yUvCUQsc4cd/ftwPaiYx8vuH0SeHut45IqmC5pqBEpkiia\nOS6SFJoDI4FQ4hBJijRMAJRUUOIQEZFIlDhERCQSJQ6pDZWSiqSG9uOQ2lApqUhqqMUhkhRqtUkg\n1OIQSQq12iQQanGIgOZIiESgxCECmiMhEoESB+jdplSP/rYkhZQ4QO8257tqXsT1tyUppMQhoou4\nSCRKHCIiEokSh8h0NEdCZBIlDpHpaO6EyCRKHKAZuTK1uVZF6W9LUkgzx0HvKue7bLb0APlUx6H8\nAXX9bUkKqcUhyVDN+RDHj+e2ry3+0EVfpKRYWhxm9hngzcBpYD/wB+5+rMR5zwB9wDAw5O4dtYxT\nAqL5ECLBiKvF8SBwibtfCvwK+PA0517l7pcpaYiIhCGWxOHuD7j7UP7uz4B1ccQhIiLRhTDG8YfA\nd6f4mgMPmNluM9s63YOY2VYz22Vmu3p6eioepMxTqooSmaRqYxxm9i/AOSW+9FF3/1b+nI8CQ8C9\nUzzMFe5+yMxagAfN7Al3f6jUie5+J3AnQEdHh8/5CYiABshFSqha4nD31033dTO7EXgT8Fp3L3mh\nd/dD+c/dZvZNYBNQMnFIyk1XMisiNRVLV5WZXQN8EHiLuw9OcU6TmWVHbwNXA4/VLkoJikpmRYIR\n1xjH54Asue6nPWZ2O4CZrTGnplIuAAAEzklEQVSz7flzVgE/NrO9wMPAd9z9e/GEKyIio2KZx+Hu\nbVMcPwRsyd9+CthYy7gkRZYunbprS60UkTkJoapKpPI0YVCkapQ4REQkEiUOERGJRIlDREQiUeIQ\nEZFIlDgknbRUiEjVaCMnSSeV3IpUjVocIiISiRKHiIhEosQhIiKRKHGIiEgkShwiIhKJTbEVRqKZ\nWQ/wbNxxRLASOBJ3ELOguGsniTGD4q6lucZ8nrs3l3NiKhNH0pjZLnfviDuOqBR37SQxZlDctVTL\nmNVVJSIikShxiIhIJEocYbgz7gBmSXHXThJjBsVdSzWLWWMcIiISiVocIiISiRJHIMzsU2b2czPb\nY2YPmNmauGMqh5l9xsyeyMf+TTM7K+6YZmJmbzezX5jZiJkFXzljZteY2ZNm1mlmH4o7nnKY2T1m\n1m1mj8UdS7nMrNXM/tXMHs//ffxJ3DGVw8wWmdnDZrY3H/efV/1nqqsqDGa21N2P52//MXCxu98c\nc1gzMrOrgR+6+5CZfRrA3T8Yc1jTMrOXAyPAHcAH3H1XzCFNyczqgV8BrwcOADuBG9z9l7EGNgMz\new3QD/yju18SdzzlMLPVwGp3f8TMssBu4K0J+F0b0OTu/WbWCPwY+BN3/1m1fqZaHIEYTRp5TUAi\nMrq7P+DuQ/m7PwPWxRlPOdz9cXd/Mu44yrQJ6HT3p9z9NPA14LqYY5qRuz8EHI07jijc/Xl3fyR/\nuw94HFgbb1Qz85z+/N3G/EdVrx9KHAExs780sy7gvwIfjzueWfhD4LtxB5Eya4GugvsHSMDFLOnM\nbD3w68COeCMpj5nVm9keoBt40N2rGrcSRw2Z2b+Y2WMlPq4DcPePunsrcC/w/nijHTdT3PlzPgoM\nkYs9duXEnBBW4lgiWqNJZWYZ4OvAnxb1BATL3Yfd/TJyLf5NZlbV7kHtAFhD7v66Mk/9CvAd4BNV\nDKdsM8VtZjcCbwJe64EMmkX4XYfuANBacH8dcCimWFIvP0bwdeBed/9G3PFE5e7HzOzfgGuAqhUm\nqMURCDNrL7j7FuCJuGKJwsyuAT4IvMXdB+OOJ4V2Au1m9jIzWwBcD9wfc0yplB9kvht43N3/Ou54\nymVmzaPVjGa2GHgdVb5+qKoqEGb2deBCctU+zwI3u/vBeKOamZl1AguBF/OHfhZ6NZiZ/S5wG9AM\nHAP2uPsb4o1qama2BfhboB64x93/MuaQZmRmXwWuJLdi62HgE+5+d6xBzcDMfhv4EfAouf9DgI+4\n+/b4opqZmV0KfJHc30cd8H/d/ZNV/ZlKHCIiEoW6qkREJBIlDhERiUSJQ0REIlHiEBGRSJQ4REQk\nEiUOkRoys++Z2TEz+3bcsYjMlhKHSG19Bnhn3EGIzIUSh0gVmNmr8nuULDKzpvw+CZe4+w+Avrjj\nE5kLrVUlUgXuvtPM7gf+AlgMfNndE7Opkch0lDhEqueT5NaaOgn8ccyxiFSMuqpEqudsIANkgUUx\nxyJSMUocItVzJ/AxcnuUfDrmWEQqRl1VIlVgZu8Chtz9K/l9w//dzH4H+HPgIiBjZgeAd7v79+OM\nVSQqrY4rIiKRqKtKREQiUeIQEZFIlDhERCQSJQ4REYlEiUNERCJR4hARkUiUOEREJBIlDhERieT/\nA3+l682ZctDcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c1ea4a7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.92\n",
      "-----------------------------\n",
      "\tConfusion Matrix\n",
      "-----------------------------\n",
      "\t\tPredicted\n",
      "\tActual\tNO\tYES\n",
      "-----------------------------\n",
      "\tNO\t 10.0 \t 1.0\n",
      "-----------------------------\n",
      "\tYES\t 1.0 \t 13.0\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def get_data(filename):\n",
    "    datamatrix = []\n",
    "    labelmatrix = []\n",
    "    fr = open(filename)\n",
    "    for line in fr.readlines():\n",
    "        lineArr = line.strip().split()\n",
    "        datamatrix.append([1.0, float(lineArr[0]), float(lineArr[1])])\n",
    "        labelmatrix.append(int(lineArr[2]))\n",
    "    return datamatrix, labelmatrix\n",
    "\n",
    "\n",
    "def plot_fit(fit_line, datamatrix, labelmatrix):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    weights = fit_line.getA()\n",
    "\n",
    "    dataarray = np.asarray(datamatrix)\n",
    "    n = dataarray.shape[0]\n",
    "\n",
    "    # Keep track of the two classes in different arrays so they can be plotted later...\n",
    "    xcord1 = []\n",
    "    ycord1 = []\n",
    "    xcord2 = []\n",
    "    ycord2 = []\n",
    "    for i in range(n):\n",
    "        if int(labelmatrix[i]) == 1:\n",
    "            xcord1.append(dataarray[i, 1])\n",
    "            ycord1.append(dataarray[i, 2])\n",
    "        else:\n",
    "            xcord2.append(dataarray[i, 1])\n",
    "            ycord2.append(dataarray[i, 2])\n",
    "    fig = plt.figure()\n",
    "\n",
    "    # Plot the data as points with different colours\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.scatter(xcord1, ycord1, s=30, c='red', marker='s')\n",
    "    ax.scatter(xcord2, ycord2, s=30, c='green')\n",
    "\n",
    "    # Plot the best-fit line\n",
    "    x = np.arange(-3.0, 3.0, 0.1)\n",
    "    y = (-weights[0] - weights[1] * x) / weights[2]\n",
    "    ax.plot(x, y)\n",
    "\n",
    "    plt.xlabel('x1')\n",
    "    plt.ylabel('x2')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def accuracy(labels, hypotheses):\n",
    "    count = 0.0\n",
    "    correct = 0.0\n",
    "\n",
    "    for l, h in zip(labels, hypotheses):\n",
    "        count += 1.0\n",
    "        if l == h:\n",
    "            correct += 1.0\n",
    "    return correct / count\n",
    "\n",
    "\n",
    "def print_confusion_matrix(labels, hypotheses):\n",
    "    tp = 0.0\n",
    "    tn = 0.0\n",
    "    fp = 0.0\n",
    "    fn = 0.0\n",
    "    count = 1.0\n",
    "    for l, h in zip(labels, hypotheses):\n",
    "        count += 1.0\n",
    "        if l == 1 and h == 1:\n",
    "            tp += 1.0\n",
    "        elif l == 1 and h == 0:\n",
    "            fn += 1.0\n",
    "        elif l == 0 and h == 0:\n",
    "            tn += 1.0\n",
    "        else:\n",
    "            fp += 1\n",
    "    print('-----------------------------')\n",
    "    print('\\tConfusion Matrix')\n",
    "    print('-----------------------------')\n",
    "    print('\\t\\tPredicted')\n",
    "    print('\\tActual\\tNO\\tYES')\n",
    "    print('-----------------------------')\n",
    "    print('\\tNO\\t', tn, '\\t', fp)\n",
    "    print('-----------------------------')\n",
    "    print('\\tYES\\t', fn, '\\t', tp)\n",
    "    print('-----------------------------')\n",
    "\n",
    "    \n",
    "X, Y = get_data('testSet.txt')\n",
    "\n",
    "clf = logistic_regression(5000)\n",
    "w = clf.fit(X, Y)\n",
    "print('Weights:', w)\n",
    "plot_fit(w, X, Y)\n",
    "\n",
    "verify_x, verify_y = get_data('verify.txt')\n",
    "hypotheses = clf.predict(verify_x)\n",
    "\n",
    "print('Accuracy:', accuracy(verify_y, hypotheses))\n",
    "\n",
    "print_confusion_matrix(verify_y, hypotheses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_and_labels(filename):\n",
    "    import pandas as pd\n",
    "    \n",
    "    df = pd.read_csv(filename, header = None, sep='\\t')\n",
    "    x = df.iloc[:,1]\n",
    "    y = df.iloc[:,0]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    POLIT\n",
       "1    POLIT\n",
       "2      NOT\n",
       "3    POLIT\n",
       "4    POLIT\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x, train_y = get_data_and_labels('/Users/Rong/Desktop/general-tweets.txt')\n",
    "test_x, test_y = get_data_and_labels('/Users/Rong/Desktop/keyword-tweets.txt')\n",
    "\n",
    "test_x.head()\n",
    "test_y.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_labels(labels):\n",
    "    \n",
    "    from sklearn import preprocessing \n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(labels)\n",
    "    return le\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = encode_labels(train_y)\n",
    "train_targets = le.transform(train_y)\n",
    "test_targets = le.transform(test_y)\n",
    "\n",
    "train_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 9048)\n",
      "(2004, 9048)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vector = CountVectorizer()\n",
    "x_train_counts = count_vector.fit_transform(train_x).toarray()\n",
    "x_test_counts = count_vector.transform(test_x).toarray()\n",
    "\n",
    "print(x_train_counts.shape)\n",
    "print(x_test_counts.shape)\n",
    "#we have 2000 instances and 9048 features \n",
    "# In this way we lose so much degrees of freedom n-p\n",
    "##### stock words are useless so we want to get rid of them as features \n",
    "### words that occur too seldom are not sufficient to warrant predictive power \n",
    "### so we get rid of them too \n",
    "# lasso regression, if we see instances of two variables occur together too often then we only take one into account?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.15618762475\n",
      "Confusion Matrix:  [[ 313    0]\n",
      " [1691    0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(x_train_counts, train_targets)\n",
    "hyp = classifier.predict(x_test_counts)\n",
    "\n",
    "print('Accuracy: ', accuracy_score(test_targets, hyp))\n",
    "print('Confusion Matrix: ', confusion_matrix(test_targets, hyp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C =  0.0001 ... accuracy:  0.15618762475\n",
      "C =  0.001 ... accuracy:  0.15618762475\n",
      "C =  0.01 ... accuracy:  0.15618762475\n",
      "C =  0.1 ... accuracy:  0.15618762475\n",
      "C =  1 ... accuracy:  0.199600798403\n",
      "C =  10 ... accuracy:  0.268962075848\n",
      "C =  100 ... accuracy:  0.288922155689\n",
      "C =  1000 ... accuracy:  0.292415169661\n",
      "C =  10000 ... accuracy:  0.273952095808\n"
     ]
    }
   ],
   "source": [
    "C = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "\n",
    "for c in C: \n",
    "    classifier = LogisticRegression(penalty ='l1', C=c)\n",
    "    classifier.fit(x_train_counts, train_targets)\n",
    "    hyp = classifier.predict(x_test_counts)\n",
    "    accuracy = accuracy_score(test_targets, hyp)\n",
    "    print('C = ', c, '... accuracy: ', accuracy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:  [[ 301   12]\n",
      " [1601   90]]\n"
     ]
    }
   ],
   "source": [
    "classifier.fit(x_train_counts, train_targets)\n",
    "hyp = classifier.predict(x_test_counts)\n",
    "print('Confusion Matrix: ', confusion_matrix(test_targets, hyp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

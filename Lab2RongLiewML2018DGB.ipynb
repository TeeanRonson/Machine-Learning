{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import statsmodels.formula.api as smf \n",
    "import statsmodels.api as sm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.948420</td>\n",
       "      <td>-0.319132</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.913813</td>\n",
       "      <td>0.125970</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.013082</td>\n",
       "      <td>5.295910</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.193497</td>\n",
       "      <td>5.823372</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.193963</td>\n",
       "      <td>5.395064</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2  type\n",
       "0  3.948420 -0.319132     1\n",
       "1  5.913813  0.125970     1\n",
       "2 -0.013082  5.295910    -1\n",
       "3 -0.193497  5.823372    -1\n",
       "4  1.193963  5.395064    -1"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read in data and check data\n",
    "os.getcwd()\n",
    "testSet = pd.read_csv(\"data.txt\", names = [\"x1\", \"x2\", \"type\"])\n",
    "testSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x1c20ba41d0>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAFgCAYAAACsSp6OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c20ba4048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Check data plot\n",
    "sns.lmplot(\"x1\", \"x2\", data=testSet, ci = None, hue=\"type\", fit_reg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading in Harrington's SMO implementation\n",
    "# %load SVMMLiA.py\n",
    "'''\n",
    "Created on Nov 4, 2010\n",
    "Chapter 5 source file for Machine Learing in Action\n",
    "@author: Peter\n",
    "'''\n",
    "from numpy import *\n",
    "from time import sleep\n",
    "\n",
    "def loadDataSet(fileName):\n",
    "    dataMat = []; labelMat = []\n",
    "    fr = open(fileName)\n",
    "    for line in fr.readlines():\n",
    "        lineArr = line.strip().split(',')\n",
    "        dataMat.append([float(lineArr[0]), float(lineArr[1])])\n",
    "        labelMat.append(float(lineArr[2]))\n",
    "    return dataMat,labelMat\n",
    "\n",
    "def selectJrand(i,m):\n",
    "    j=i #we want to select any J not equal to i\n",
    "    while (j==i):\n",
    "        j = int(random.uniform(0,m))\n",
    "    return j\n",
    "\n",
    "def clipAlpha(aj,H,L):\n",
    "    if aj > H: \n",
    "        aj = H\n",
    "    if L > aj:\n",
    "        aj = L\n",
    "    return aj\n",
    "\n",
    "def smoSimple(dataMatIn, classLabels, C, toler, maxIter):\n",
    "    dataMatrix = mat(dataMatIn); labelMat = mat(classLabels).transpose()\n",
    "    b = 0; m,n = shape(dataMatrix)\n",
    "    alphas = mat(zeros((m,1)))\n",
    "    iter = 0\n",
    "    while (iter < maxIter):\n",
    "        alphaPairsChanged = 0\n",
    "        for i in range(m):\n",
    "            fXi = float(multiply(alphas,labelMat).T*(dataMatrix*dataMatrix[i,:].T)) + b\n",
    "            Ei = fXi - float(labelMat[i])#if checks if an example violates KKT conditions\n",
    "            if ((labelMat[i]*Ei < -toler) and (alphas[i] < C)) or ((labelMat[i]*Ei > toler) and (alphas[i] > 0)):\n",
    "                j = selectJrand(i,m)\n",
    "                fXj = float(multiply(alphas,labelMat).T*(dataMatrix*dataMatrix[j,:].T)) + b\n",
    "                Ej = fXj - float(labelMat[j])\n",
    "                alphaIold = alphas[i].copy(); alphaJold = alphas[j].copy();\n",
    "                if (labelMat[i] != labelMat[j]):\n",
    "                    L = max(0, alphas[j] - alphas[i])\n",
    "                    H = min(C, C + alphas[j] - alphas[i])\n",
    "                else:\n",
    "                    L = max(0, alphas[j] + alphas[i] - C)\n",
    "                    H = min(C, alphas[j] + alphas[i])\n",
    "                if L==H: print(\"L==H\"); continue\n",
    "                eta = 2.0 * dataMatrix[i,:]*dataMatrix[j,:].T - dataMatrix[i,:]*dataMatrix[i,:].T - dataMatrix[j,:]*dataMatrix[j,:].T\n",
    "                if eta >= 0: print(\"eta>=0\"); continue\n",
    "                alphas[j] -= labelMat[j]*(Ei - Ej)/eta\n",
    "                alphas[j] = clipAlpha(alphas[j],H,L)\n",
    "                if (abs(alphas[j] - alphaJold) < 0.00001): print(\"j not moving enough\"); continue\n",
    "                alphas[i] += labelMat[j]*labelMat[i]*(alphaJold - alphas[j])#update i by the same amount as j\n",
    "                                                                        #the update is in the oppostie direction\n",
    "                b1 = b - Ei- labelMat[i]*(alphas[i]-alphaIold)*dataMatrix[i,:]*dataMatrix[i,:].T - labelMat[j]*(alphas[j]-alphaJold)*dataMatrix[i,:]*dataMatrix[j,:].T\n",
    "                b2 = b - Ej- labelMat[i]*(alphas[i]-alphaIold)*dataMatrix[i,:]*dataMatrix[j,:].T - labelMat[j]*(alphas[j]-alphaJold)*dataMatrix[j,:]*dataMatrix[j,:].T\n",
    "                if (0 < alphas[i]) and (C > alphas[i]): b = b1\n",
    "                elif (0 < alphas[j]) and (C > alphas[j]): b = b2\n",
    "                else: b = (b1 + b2)/2.0\n",
    "                alphaPairsChanged += 1\n",
    "                print(\"iter: %d i:%d, pairs changed %d\" % (iter,i,alphaPairsChanged))\n",
    "        if (alphaPairsChanged == 0): iter += 1\n",
    "        else: iter = 0\n",
    "        print(\"iteration number: %d\" % iter)\n",
    "    return b,alphas\n",
    "\n",
    "def kernelTrans(X, A, kTup): #calc the kernel or transform data to a higher dimensional space\n",
    "    m,n = shape(X)\n",
    "    K = mat(zeros((m,1)))\n",
    "    if kTup[0]=='lin': K = X * A.T   #linear kernel\n",
    "    elif kTup[0]=='rbf':\n",
    "        for j in range(m):\n",
    "            deltaRow = X[j,:] - A\n",
    "            K[j] = deltaRow*deltaRow.T\n",
    "        K = exp(K/(-1*kTup[1]**2)) #divide in NumPy is element-wise not matrix like Matlab\n",
    "    else: raise NameError('Houston We Have a Problem -- \\\n",
    "    That Kernel is not recognized')\n",
    "    return K\n",
    "\n",
    "class optStruct:\n",
    "    def __init__(self,dataMatIn, classLabels, C, toler, kTup):  # Initialize the structure with the parameters \n",
    "        self.X = dataMatIn\n",
    "        self.labelMat = classLabels\n",
    "        self.C = C\n",
    "        self.tol = toler\n",
    "        self.m = shape(dataMatIn)[0]\n",
    "        self.alphas = mat(zeros((self.m,1)))\n",
    "        self.b = 0\n",
    "        self.eCache = mat(zeros((self.m,2))) #first column is valid flag\n",
    "        self.K = mat(zeros((self.m,self.m)))\n",
    "        for i in range(self.m):\n",
    "            self.K[:,i] = kernelTrans(self.X, self.X[i,:], kTup)\n",
    "        \n",
    "def calcEk(oS, k):\n",
    "    fXk = float(multiply(oS.alphas,oS.labelMat).T*oS.K[:,k] + oS.b)\n",
    "    Ek = fXk - float(oS.labelMat[k])\n",
    "    return Ek\n",
    "        \n",
    "def selectJ(i, oS, Ei):         #this is the second choice -heurstic, and calcs Ej\n",
    "    maxK = -1; maxDeltaE = 0; Ej = 0\n",
    "    oS.eCache[i] = [1,Ei]  #set valid #choose the alpha that gives the maximum delta E\n",
    "    validEcacheList = nonzero(oS.eCache[:,0].A)[0]\n",
    "    if (len(validEcacheList)) > 1:\n",
    "        for k in validEcacheList:   #loop through valid Ecache values and find the one that maximizes delta E\n",
    "            if k == i: continue #don't calc for i, waste of time\n",
    "            Ek = calcEk(oS, k)\n",
    "            deltaE = abs(Ei - Ek)\n",
    "            if (deltaE > maxDeltaE):\n",
    "                maxK = k; maxDeltaE = deltaE; Ej = Ek\n",
    "        return maxK, Ej\n",
    "    else:   #in this case (first time around) we don't have any valid eCache values\n",
    "        j = selectJrand(i, oS.m)\n",
    "        Ej = calcEk(oS, j)\n",
    "    return j, Ej\n",
    "\n",
    "def updateEk(oS, k):#after any alpha has changed update the new value in the cache\n",
    "    Ek = calcEk(oS, k)\n",
    "    oS.eCache[k] = [1,Ek]\n",
    "        \n",
    "def innerL(i, oS):\n",
    "    Ei = calcEk(oS, i)\n",
    "    if ((oS.labelMat[i]*Ei < -oS.tol) and (oS.alphas[i] < oS.C)) or ((oS.labelMat[i]*Ei > oS.tol) and (oS.alphas[i] > 0)):\n",
    "        j,Ej = selectJ(i, oS, Ei) #this has been changed from selectJrand\n",
    "        alphaIold = oS.alphas[i].copy(); alphaJold = oS.alphas[j].copy();\n",
    "        if (oS.labelMat[i] != oS.labelMat[j]):\n",
    "            L = max(0, oS.alphas[j] - oS.alphas[i])\n",
    "            H = min(oS.C, oS.C + oS.alphas[j] - oS.alphas[i])\n",
    "        else:\n",
    "            L = max(0, oS.alphas[j] + oS.alphas[i] - oS.C)\n",
    "            H = min(oS.C, oS.alphas[j] + oS.alphas[i])\n",
    "        if L==H: print(\"L==H\"); return 0\n",
    "        eta = 2.0 * oS.K[i,j] - oS.K[i,i] - oS.K[j,j] #changed for kernel\n",
    "        if eta >= 0: print(\"eta>=0\"); return 0\n",
    "        oS.alphas[j] -= oS.labelMat[j]*(Ei - Ej)/eta\n",
    "        oS.alphas[j] = clipAlpha(oS.alphas[j],H,L)\n",
    "        updateEk(oS, j) #added this for the Ecache\n",
    "        if (abs(oS.alphas[j] - alphaJold) < 0.00001): print(\"j not moving enough\"); return 0\n",
    "        oS.alphas[i] += oS.labelMat[j]*oS.labelMat[i]*(alphaJold - oS.alphas[j])#update i by the same amount as j\n",
    "        updateEk(oS, i) #added this for the Ecache                    #the update is in the oppostie direction\n",
    "        b1 = oS.b - Ei- oS.labelMat[i]*(oS.alphas[i]-alphaIold)*oS.K[i,i] - oS.labelMat[j]*(oS.alphas[j]-alphaJold)*oS.K[i,j]\n",
    "        b2 = oS.b - Ej- oS.labelMat[i]*(oS.alphas[i]-alphaIold)*oS.K[i,j]- oS.labelMat[j]*(oS.alphas[j]-alphaJold)*oS.K[j,j]\n",
    "        if (0 < oS.alphas[i]) and (oS.C > oS.alphas[i]): oS.b = b1\n",
    "        elif (0 < oS.alphas[j]) and (oS.C > oS.alphas[j]): oS.b = b2\n",
    "        else: oS.b = (b1 + b2)/2.0\n",
    "        return 1\n",
    "    else: return 0\n",
    "\n",
    "def smoP(dataMatIn, classLabels, C, toler, maxIter,kTup=('lin', 0)):    #full Platt SMO\n",
    "    oS = optStruct(mat(dataMatIn),mat(classLabels).transpose(),C,toler, kTup)\n",
    "    iter = 0\n",
    "    entireSet = True; alphaPairsChanged = 0\n",
    "    while (iter < maxIter) and ((alphaPairsChanged > 0) or (entireSet)):\n",
    "        alphaPairsChanged = 0\n",
    "        if entireSet:   #go over all\n",
    "            for i in range(oS.m):        \n",
    "                alphaPairsChanged += innerL(i,oS)\n",
    "                print(\"fullSet, iter: %d i:%d, pairs changed %d\" % (iter,i,alphaPairsChanged))\n",
    "            iter += 1\n",
    "        else:#go over non-bound (railed) alphas\n",
    "            nonBoundIs = nonzero((oS.alphas.A > 0) * (oS.alphas.A < C))[0]\n",
    "            for i in nonBoundIs:\n",
    "                alphaPairsChanged += innerL(i,oS)\n",
    "                print(\"non-bound, iter: %d i:%d, pairs changed %d\" % (iter,i,alphaPairsChanged))\n",
    "            iter += 1\n",
    "        if entireSet: entireSet = False #toggle entire set loop\n",
    "        elif (alphaPairsChanged == 0): entireSet = True  \n",
    "        print(\"iteration number: %d\" % iter)\n",
    "    return oS.b,oS.alphas\n",
    "\n",
    "def calcWs(alphas,dataArr,classLabels):\n",
    "    X = mat(dataArr); labelMat = mat(classLabels).transpose()\n",
    "    m,n = shape(X)\n",
    "    w = zeros((n,1))\n",
    "    for i in range(m):\n",
    "        w += multiply(alphas[i]*labelMat[i],X[i,:].T)\n",
    "    return w\n",
    "\n",
    "def testRbf(k1=1.3):\n",
    "    dataArr,labelArr = loadDataSet('testSetRBF.txt')\n",
    "    b,alphas = smoP(dataArr, labelArr, 200, 0.0001, 10000, ('rbf', k1)) #C=200 important\n",
    "    datMat=mat(dataArr); labelMat = mat(labelArr).transpose()\n",
    "    svInd=nonzero(alphas.A>0)[0]\n",
    "    sVs=datMat[svInd] #get matrix of only support vectors\n",
    "    labelSV = labelMat[svInd];\n",
    "    print(\"there are %d Support Vectors\" % shape(sVs)[0])\n",
    "    m,n = shape(datMat)\n",
    "    errorCount = 0\n",
    "    for i in range(m):\n",
    "        kernelEval = kernelTrans(sVs,datMat[i,:],('rbf', k1))\n",
    "        predict=kernelEval.T * multiply(labelSV,alphas[svInd]) + b\n",
    "        if sign(predict)!=sign(labelArr[i]): errorCount += 1\n",
    "    print(\"the training error rate is: %f\" % (float(errorCount)/m))\n",
    "    dataArr,labelArr = loadDataSet('testSetRBF2.txt')\n",
    "    errorCount = 0\n",
    "    datMat=mat(dataArr); labelMat = mat(labelArr).transpose()\n",
    "    m,n = shape(datMat)\n",
    "    for i in range(m):\n",
    "        kernelEval = kernelTrans(sVs,datMat[i,:],('rbf', k1))\n",
    "        predict=kernelEval.T * multiply(labelSV,alphas[svInd]) + b\n",
    "        if sign(predict)!=sign(labelArr[i]): errorCount += 1    \n",
    "    print(\"the test error rate is: %f\" % (float(errorCount)/m))    \n",
    "    \n",
    "def img2vector(filename):\n",
    "    returnVect = zeros((1,1024))\n",
    "    fr = open(filename)\n",
    "    for i in range(32):\n",
    "        lineStr = fr.readline()\n",
    "        for j in range(32):\n",
    "            returnVect[0,32*i+j] = int(lineStr[j])\n",
    "    return returnVect\n",
    "\n",
    "def loadImages(dirName):\n",
    "    from os import listdir\n",
    "    hwLabels = []\n",
    "    trainingFileList = listdir(dirName)           #load the training set\n",
    "    m = len(trainingFileList)\n",
    "    trainingMat = zeros((m,1024))\n",
    "    for i in range(m):\n",
    "        fileNameStr = trainingFileList[i]\n",
    "        fileStr = fileNameStr.split('.')[0]     #take off .txt\n",
    "        classNumStr = int(fileStr.split('_')[0])\n",
    "        if classNumStr == 9: hwLabels.append(-1)\n",
    "        else: hwLabels.append(1)\n",
    "        trainingMat[i,:] = img2vector('%s/%s' % (dirName, fileNameStr))\n",
    "    return trainingMat, hwLabels    \n",
    "\n",
    "def testDigits(kTup=('rbf', 10)):\n",
    "    dataArr,labelArr = loadImages('trainingDigits')\n",
    "    b,alphas = smoP(dataArr, labelArr, 200, 0.0001, 10000, kTup)\n",
    "    datMat=mat(dataArr); labelMat = mat(labelArr).transpose()\n",
    "    svInd=nonzero(alphas.A>0)[0]\n",
    "    sVs=datMat[svInd] \n",
    "    labelSV = labelMat[svInd];\n",
    "    print(\"there are %d Support Vectors\" % shape(sVs)[0])\n",
    "    m,n = shape(datMat)\n",
    "    errorCount = 0\n",
    "    for i in range(m):\n",
    "        kernelEval = kernelTrans(sVs,datMat[i,:],kTup)\n",
    "        predict=kernelEval.T * multiply(labelSV,alphas[svInd]) + b\n",
    "        if sign(predict)!=sign(labelArr[i]): errorCount += 1\n",
    "    print(\"the training error rate is: %f\" % (float(errorCount)/m))\n",
    "    dataArr,labelArr = loadImages('testDigits')\n",
    "    errorCount = 0\n",
    "    datMat=mat(dataArr); labelMat = mat(labelArr).transpose()\n",
    "    m,n = shape(datMat)\n",
    "    for i in range(m):\n",
    "        kernelEval = kernelTrans(sVs,datMat[i,:],kTup)\n",
    "        predict=kernelEval.T * multiply(labelSV,alphas[svInd]) + b\n",
    "        if sign(predict)!=sign(labelArr[i]): errorCount += 1    \n",
    "    print(\"the test error rate is: %f\" % (float(errorCount)/m)) \n",
    "\n",
    "\n",
    "'''#######********************************\n",
    "Non-Kernel VErsions below\n",
    "'''#######********************************\n",
    "\n",
    "class optStructK:\n",
    "    def __init__(self,dataMatIn, classLabels, C, toler):  # Initialize the structure with the parameters \n",
    "        self.X = dataMatIn\n",
    "        self.labelMat = classLabels\n",
    "        self.C = C\n",
    "        self.tol = toler\n",
    "        self.m = shape(dataMatIn)[0]\n",
    "        self.alphas = mat(zeros((self.m,1)))\n",
    "        self.b = 0\n",
    "        self.eCache = mat(zeros((self.m,2))) #first column is valid flag\n",
    "        \n",
    "def calcEkK(oS, k):\n",
    "    fXk = float(multiply(oS.alphas,oS.labelMat).T*(oS.X*oS.X[k,:].T)) + oS.b\n",
    "    Ek = fXk - float(oS.labelMat[k])\n",
    "    return Ek\n",
    "        \n",
    "def selectJK(i, oS, Ei):         #this is the second choice -heurstic, and calcs Ej\n",
    "    maxK = -1; maxDeltaE = 0; Ej = 0\n",
    "    oS.eCache[i] = [1,Ei]  #set valid #choose the alpha that gives the maximum delta E\n",
    "    validEcacheList = nonzero(oS.eCache[:,0].A)[0]\n",
    "    if (len(validEcacheList)) > 1:\n",
    "        for k in validEcacheList:   #loop through valid Ecache values and find the one that maximizes delta E\n",
    "            if k == i: continue #don't calc for i, waste of time\n",
    "            Ek = calcEkK(oS, k)\n",
    "            deltaE = abs(Ei - Ek)\n",
    "            if (deltaE > maxDeltaE):\n",
    "                maxK = k; maxDeltaE = deltaE; Ej = Ek\n",
    "        return maxK, Ej\n",
    "    else:   #in this case (first time around) we don't have any valid eCache values\n",
    "        j = selectJrand(i, oS.m)\n",
    "        Ej = calcEkK(oS, j)\n",
    "    return j, Ej\n",
    "\n",
    "def updateEkK(oS, k):#after any alpha has changed update the new value in the cache\n",
    "    Ek = calcEkK(oS, k)\n",
    "    oS.eCache[k] = [1,Ek]\n",
    "        \n",
    "def innerLK(i, oS):\n",
    "    Ei = calcEkK(oS, i)\n",
    "    if ((oS.labelMat[i]*Ei < -oS.tol) and (oS.alphas[i] < oS.C)) or ((oS.labelMat[i]*Ei > oS.tol) and (oS.alphas[i] > 0)):\n",
    "        j,Ej = selectJK(i, oS, Ei) #this has been changed from selectJrand\n",
    "        alphaIold = oS.alphas[i].copy(); alphaJold = oS.alphas[j].copy();\n",
    "        if (oS.labelMat[i] != oS.labelMat[j]):\n",
    "            L = max(0, oS.alphas[j] - oS.alphas[i])\n",
    "            H = min(oS.C, oS.C + oS.alphas[j] - oS.alphas[i])\n",
    "        else:\n",
    "            L = max(0, oS.alphas[j] + oS.alphas[i] - oS.C)\n",
    "            H = min(oS.C, oS.alphas[j] + oS.alphas[i])\n",
    "        if L==H: print(\"L==H\"); return 0\n",
    "        eta = 2.0 * oS.X[i,:]*oS.X[j,:].T - oS.X[i,:]*oS.X[i,:].T - oS.X[j,:]*oS.X[j,:].T\n",
    "        if eta >= 0: print(\"eta>=0\"); return 0\n",
    "        oS.alphas[j] -= oS.labelMat[j]*(Ei - Ej)/eta\n",
    "        oS.alphas[j] = clipAlpha(oS.alphas[j],H,L)\n",
    "        updateEkK(oS, j) #added this for the Ecache\n",
    "        if (abs(oS.alphas[j] - alphaJold) < 0.00001): print(\"j not moving enough\"); return 0\n",
    "        oS.alphas[i] += oS.labelMat[j]*oS.labelMat[i]*(alphaJold - oS.alphas[j])#update i by the same amount as j\n",
    "        updateEkK(oS, i) #added this for the Ecache                    #the update is in the oppostie direction\n",
    "        b1 = oS.b - Ei- oS.labelMat[i]*(oS.alphas[i]-alphaIold)*oS.X[i,:]*oS.X[i,:].T - oS.labelMat[j]*(oS.alphas[j]-alphaJold)*oS.X[i,:]*oS.X[j,:].T\n",
    "        b2 = oS.b - Ej- oS.labelMat[i]*(oS.alphas[i]-alphaIold)*oS.X[i,:]*oS.X[j,:].T - oS.labelMat[j]*(oS.alphas[j]-alphaJold)*oS.X[j,:]*oS.X[j,:].T\n",
    "        if (0 < oS.alphas[i]) and (oS.C > oS.alphas[i]): oS.b = b1\n",
    "        elif (0 < oS.alphas[j]) and (oS.C > oS.alphas[j]): oS.b = b2\n",
    "        else: oS.b = (b1 + b2)/2.0\n",
    "        return 1\n",
    "    else: return 0\n",
    "\n",
    "def smoPK(dataMatIn, classLabels, C, toler, maxIter):    #full Platt SMO\n",
    "    oS = optStructK(mat(dataMatIn),mat(classLabels).transpose(),C,toler)\n",
    "    iter = 0\n",
    "    entireSet = True; alphaPairsChanged = 0\n",
    "    while (iter < maxIter) and ((alphaPairsChanged > 0) or (entireSet)):\n",
    "        alphaPairsChanged = 0\n",
    "        if entireSet:   #go over all\n",
    "            for i in range(oS.m):        \n",
    "                alphaPairsChanged += innerLK(i,oS)\n",
    "                print(\"fullSet, iter: %d i:%d, pairs changed %d\" % (iter,i,alphaPairsChanged))\n",
    "            iter += 1\n",
    "        else:#go over non-bound (railed) alphas\n",
    "            nonBoundIs = nonzero((oS.alphas.A > 0) * (oS.alphas.A < C))[0]\n",
    "            for i in nonBoundIs:\n",
    "                alphaPairsChanged += innerLK(i,oS)\n",
    "                print(\"non-bound, iter: %d i:%d, pairs changed %d\" % (iter,i,alphaPairsChanged))\n",
    "            iter += 1\n",
    "        if entireSet: entireSet = False #toggle entire set loop\n",
    "        elif (alphaPairsChanged == 0): entireSet = True  \n",
    "        print(\"iteration number: %d\" % iter)\n",
    "    return oS.b,oS.alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating class svm_basic - Lab2 starts here\n",
    "class svm_basic:\n",
    "    \n",
    "    #Constructor\n",
    "    def __init__(self, C = 1, toler = 0.001, maxIter = 50):\n",
    "        self.C = C\n",
    "        self.toler = toler\n",
    "        self.maxIter = maxIter\n",
    "        \n",
    "    #Fit function - inputs data Matrix and Class Labels    \n",
    "    def fit(self, X, Y): \n",
    "        self.b, self.alphas = smoPK(X, Y, self.C, self.toler, self.maxIter)\n",
    "        #print(self.alphas)\n",
    "        self.w = calcWs(self.alphas, X, Y)\n",
    "        return \n",
    "    \n",
    "    #Predict function - inputs test Matrix \n",
    "    #Uses hyperplane function\n",
    "    def predict(self, X):\n",
    "        from numpy import dot\n",
    "        \n",
    "        result = dot(self.w.T,X) + self.b\n",
    "        return result\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L==H\n",
      "fullSet, iter: 0 i:0, pairs changed 0\n",
      "L==H\n",
      "fullSet, iter: 0 i:1, pairs changed 0\n",
      "fullSet, iter: 0 i:2, pairs changed 1\n",
      "fullSet, iter: 0 i:3, pairs changed 1\n",
      "fullSet, iter: 0 i:4, pairs changed 2\n",
      "L==H\n",
      "fullSet, iter: 0 i:5, pairs changed 2\n",
      "fullSet, iter: 0 i:6, pairs changed 2\n",
      "L==H\n",
      "fullSet, iter: 0 i:7, pairs changed 2\n",
      "fullSet, iter: 0 i:8, pairs changed 3\n",
      "fullSet, iter: 0 i:9, pairs changed 3\n",
      "fullSet, iter: 0 i:10, pairs changed 3\n",
      "fullSet, iter: 0 i:11, pairs changed 4\n",
      "j not moving enough\n",
      "fullSet, iter: 0 i:12, pairs changed 4\n",
      "j not moving enough\n",
      "fullSet, iter: 0 i:13, pairs changed 4\n",
      "fullSet, iter: 0 i:14, pairs changed 4\n",
      "fullSet, iter: 0 i:15, pairs changed 4\n",
      "j not moving enough\n",
      "fullSet, iter: 0 i:16, pairs changed 4\n",
      "fullSet, iter: 0 i:17, pairs changed 4\n",
      "fullSet, iter: 0 i:18, pairs changed 5\n",
      "fullSet, iter: 0 i:19, pairs changed 5\n",
      "fullSet, iter: 0 i:20, pairs changed 5\n",
      "fullSet, iter: 0 i:21, pairs changed 5\n",
      "fullSet, iter: 0 i:22, pairs changed 5\n",
      "fullSet, iter: 0 i:23, pairs changed 5\n",
      "fullSet, iter: 0 i:24, pairs changed 5\n",
      "fullSet, iter: 0 i:25, pairs changed 5\n",
      "fullSet, iter: 0 i:26, pairs changed 5\n",
      "fullSet, iter: 0 i:27, pairs changed 5\n",
      "fullSet, iter: 0 i:28, pairs changed 5\n",
      "fullSet, iter: 0 i:29, pairs changed 5\n",
      "fullSet, iter: 0 i:30, pairs changed 5\n",
      "fullSet, iter: 0 i:31, pairs changed 5\n",
      "fullSet, iter: 0 i:32, pairs changed 5\n",
      "fullSet, iter: 0 i:33, pairs changed 5\n",
      "j not moving enough\n",
      "fullSet, iter: 0 i:34, pairs changed 5\n",
      "fullSet, iter: 0 i:35, pairs changed 5\n",
      "fullSet, iter: 0 i:36, pairs changed 5\n",
      "fullSet, iter: 0 i:37, pairs changed 5\n",
      "fullSet, iter: 0 i:38, pairs changed 5\n",
      "fullSet, iter: 0 i:39, pairs changed 5\n",
      "fullSet, iter: 0 i:40, pairs changed 5\n",
      "fullSet, iter: 0 i:41, pairs changed 5\n",
      "fullSet, iter: 0 i:42, pairs changed 5\n",
      "L==H\n",
      "fullSet, iter: 0 i:43, pairs changed 5\n",
      "fullSet, iter: 0 i:44, pairs changed 5\n",
      "fullSet, iter: 0 i:45, pairs changed 5\n",
      "fullSet, iter: 0 i:46, pairs changed 5\n",
      "fullSet, iter: 0 i:47, pairs changed 5\n",
      "fullSet, iter: 0 i:48, pairs changed 5\n",
      "fullSet, iter: 0 i:49, pairs changed 5\n",
      "fullSet, iter: 0 i:50, pairs changed 5\n",
      "fullSet, iter: 0 i:51, pairs changed 5\n",
      "fullSet, iter: 0 i:52, pairs changed 5\n",
      "fullSet, iter: 0 i:53, pairs changed 5\n",
      "j not moving enough\n",
      "fullSet, iter: 0 i:54, pairs changed 5\n",
      "fullSet, iter: 0 i:55, pairs changed 5\n",
      "fullSet, iter: 0 i:56, pairs changed 5\n",
      "fullSet, iter: 0 i:57, pairs changed 5\n",
      "fullSet, iter: 0 i:58, pairs changed 5\n",
      "fullSet, iter: 0 i:59, pairs changed 5\n",
      "fullSet, iter: 0 i:60, pairs changed 5\n",
      "fullSet, iter: 0 i:61, pairs changed 5\n",
      "fullSet, iter: 0 i:62, pairs changed 5\n",
      "fullSet, iter: 0 i:63, pairs changed 5\n",
      "fullSet, iter: 0 i:64, pairs changed 5\n",
      "fullSet, iter: 0 i:65, pairs changed 5\n",
      "fullSet, iter: 0 i:66, pairs changed 5\n",
      "fullSet, iter: 0 i:67, pairs changed 5\n",
      "fullSet, iter: 0 i:68, pairs changed 5\n",
      "fullSet, iter: 0 i:69, pairs changed 5\n",
      "fullSet, iter: 0 i:70, pairs changed 5\n",
      "fullSet, iter: 0 i:71, pairs changed 5\n",
      "fullSet, iter: 0 i:72, pairs changed 5\n",
      "fullSet, iter: 0 i:73, pairs changed 5\n",
      "fullSet, iter: 0 i:74, pairs changed 5\n",
      "fullSet, iter: 0 i:75, pairs changed 5\n",
      "fullSet, iter: 0 i:76, pairs changed 5\n",
      "fullSet, iter: 0 i:77, pairs changed 5\n",
      "fullSet, iter: 0 i:78, pairs changed 5\n",
      "fullSet, iter: 0 i:79, pairs changed 5\n",
      "fullSet, iter: 0 i:80, pairs changed 5\n",
      "fullSet, iter: 0 i:81, pairs changed 5\n",
      "fullSet, iter: 0 i:82, pairs changed 5\n",
      "fullSet, iter: 0 i:83, pairs changed 5\n",
      "fullSet, iter: 0 i:84, pairs changed 5\n",
      "fullSet, iter: 0 i:85, pairs changed 5\n",
      "fullSet, iter: 0 i:86, pairs changed 5\n",
      "fullSet, iter: 0 i:87, pairs changed 5\n",
      "fullSet, iter: 0 i:88, pairs changed 5\n",
      "fullSet, iter: 0 i:89, pairs changed 5\n",
      "fullSet, iter: 0 i:90, pairs changed 5\n",
      "fullSet, iter: 0 i:91, pairs changed 5\n",
      "fullSet, iter: 0 i:92, pairs changed 5\n",
      "fullSet, iter: 0 i:93, pairs changed 5\n",
      "fullSet, iter: 0 i:94, pairs changed 5\n",
      "fullSet, iter: 0 i:95, pairs changed 5\n",
      "fullSet, iter: 0 i:96, pairs changed 5\n",
      "fullSet, iter: 0 i:97, pairs changed 5\n",
      "fullSet, iter: 0 i:98, pairs changed 5\n",
      "fullSet, iter: 0 i:99, pairs changed 5\n",
      "iteration number: 1\n",
      "j not moving enough\n",
      "non-bound, iter: 1 i:0, pairs changed 0\n",
      "j not moving enough\n",
      "non-bound, iter: 1 i:4, pairs changed 0\n",
      "non-bound, iter: 1 i:7, pairs changed 0\n",
      "j not moving enough\n",
      "non-bound, iter: 1 i:8, pairs changed 0\n",
      "j not moving enough\n",
      "non-bound, iter: 1 i:11, pairs changed 0\n",
      "non-bound, iter: 1 i:18, pairs changed 0\n",
      "iteration number: 2\n",
      "j not moving enough\n",
      "fullSet, iter: 2 i:0, pairs changed 0\n",
      "fullSet, iter: 2 i:1, pairs changed 0\n",
      "fullSet, iter: 2 i:2, pairs changed 0\n",
      "fullSet, iter: 2 i:3, pairs changed 0\n",
      "j not moving enough\n",
      "fullSet, iter: 2 i:4, pairs changed 0\n",
      "fullSet, iter: 2 i:5, pairs changed 0\n",
      "fullSet, iter: 2 i:6, pairs changed 0\n",
      "fullSet, iter: 2 i:7, pairs changed 0\n",
      "j not moving enough\n",
      "fullSet, iter: 2 i:8, pairs changed 0\n",
      "fullSet, iter: 2 i:9, pairs changed 0\n",
      "fullSet, iter: 2 i:10, pairs changed 0\n",
      "j not moving enough\n",
      "fullSet, iter: 2 i:11, pairs changed 0\n",
      "fullSet, iter: 2 i:12, pairs changed 0\n",
      "fullSet, iter: 2 i:13, pairs changed 0\n",
      "fullSet, iter: 2 i:14, pairs changed 0\n",
      "fullSet, iter: 2 i:15, pairs changed 0\n",
      "fullSet, iter: 2 i:16, pairs changed 0\n",
      "fullSet, iter: 2 i:17, pairs changed 0\n",
      "fullSet, iter: 2 i:18, pairs changed 0\n",
      "fullSet, iter: 2 i:19, pairs changed 0\n",
      "fullSet, iter: 2 i:20, pairs changed 0\n",
      "fullSet, iter: 2 i:21, pairs changed 0\n",
      "fullSet, iter: 2 i:22, pairs changed 0\n",
      "fullSet, iter: 2 i:23, pairs changed 0\n",
      "fullSet, iter: 2 i:24, pairs changed 0\n",
      "fullSet, iter: 2 i:25, pairs changed 0\n",
      "fullSet, iter: 2 i:26, pairs changed 0\n",
      "fullSet, iter: 2 i:27, pairs changed 0\n",
      "fullSet, iter: 2 i:28, pairs changed 0\n",
      "fullSet, iter: 2 i:29, pairs changed 0\n",
      "fullSet, iter: 2 i:30, pairs changed 0\n",
      "fullSet, iter: 2 i:31, pairs changed 0\n",
      "fullSet, iter: 2 i:32, pairs changed 0\n",
      "fullSet, iter: 2 i:33, pairs changed 0\n",
      "j not moving enough\n",
      "fullSet, iter: 2 i:34, pairs changed 0\n",
      "fullSet, iter: 2 i:35, pairs changed 0\n",
      "fullSet, iter: 2 i:36, pairs changed 0\n",
      "fullSet, iter: 2 i:37, pairs changed 0\n",
      "fullSet, iter: 2 i:38, pairs changed 0\n",
      "fullSet, iter: 2 i:39, pairs changed 0\n",
      "fullSet, iter: 2 i:40, pairs changed 0\n",
      "fullSet, iter: 2 i:41, pairs changed 0\n",
      "fullSet, iter: 2 i:42, pairs changed 0\n",
      "L==H\n",
      "fullSet, iter: 2 i:43, pairs changed 0\n",
      "fullSet, iter: 2 i:44, pairs changed 0\n",
      "fullSet, iter: 2 i:45, pairs changed 0\n",
      "fullSet, iter: 2 i:46, pairs changed 0\n",
      "fullSet, iter: 2 i:47, pairs changed 0\n",
      "fullSet, iter: 2 i:48, pairs changed 0\n",
      "fullSet, iter: 2 i:49, pairs changed 0\n",
      "fullSet, iter: 2 i:50, pairs changed 0\n",
      "fullSet, iter: 2 i:51, pairs changed 0\n",
      "fullSet, iter: 2 i:52, pairs changed 0\n",
      "fullSet, iter: 2 i:53, pairs changed 0\n",
      "j not moving enough\n",
      "fullSet, iter: 2 i:54, pairs changed 0\n",
      "fullSet, iter: 2 i:55, pairs changed 0\n",
      "fullSet, iter: 2 i:56, pairs changed 0\n",
      "fullSet, iter: 2 i:57, pairs changed 0\n",
      "fullSet, iter: 2 i:58, pairs changed 0\n",
      "fullSet, iter: 2 i:59, pairs changed 0\n",
      "fullSet, iter: 2 i:60, pairs changed 0\n",
      "fullSet, iter: 2 i:61, pairs changed 0\n",
      "fullSet, iter: 2 i:62, pairs changed 0\n",
      "fullSet, iter: 2 i:63, pairs changed 0\n",
      "fullSet, iter: 2 i:64, pairs changed 0\n",
      "fullSet, iter: 2 i:65, pairs changed 0\n",
      "fullSet, iter: 2 i:66, pairs changed 0\n",
      "fullSet, iter: 2 i:67, pairs changed 0\n",
      "fullSet, iter: 2 i:68, pairs changed 0\n",
      "fullSet, iter: 2 i:69, pairs changed 0\n",
      "fullSet, iter: 2 i:70, pairs changed 0\n",
      "fullSet, iter: 2 i:71, pairs changed 0\n",
      "fullSet, iter: 2 i:72, pairs changed 0\n",
      "fullSet, iter: 2 i:73, pairs changed 0\n",
      "fullSet, iter: 2 i:74, pairs changed 0\n",
      "fullSet, iter: 2 i:75, pairs changed 0\n",
      "fullSet, iter: 2 i:76, pairs changed 0\n",
      "fullSet, iter: 2 i:77, pairs changed 0\n",
      "fullSet, iter: 2 i:78, pairs changed 0\n",
      "fullSet, iter: 2 i:79, pairs changed 0\n",
      "fullSet, iter: 2 i:80, pairs changed 0\n",
      "fullSet, iter: 2 i:81, pairs changed 0\n",
      "fullSet, iter: 2 i:82, pairs changed 0\n",
      "fullSet, iter: 2 i:83, pairs changed 0\n",
      "fullSet, iter: 2 i:84, pairs changed 0\n",
      "fullSet, iter: 2 i:85, pairs changed 0\n",
      "fullSet, iter: 2 i:86, pairs changed 0\n",
      "fullSet, iter: 2 i:87, pairs changed 0\n",
      "fullSet, iter: 2 i:88, pairs changed 0\n",
      "fullSet, iter: 2 i:89, pairs changed 0\n",
      "fullSet, iter: 2 i:90, pairs changed 0\n",
      "fullSet, iter: 2 i:91, pairs changed 0\n",
      "fullSet, iter: 2 i:92, pairs changed 0\n",
      "fullSet, iter: 2 i:93, pairs changed 0\n",
      "fullSet, iter: 2 i:94, pairs changed 0\n",
      "fullSet, iter: 2 i:95, pairs changed 0\n",
      "fullSet, iter: 2 i:96, pairs changed 0\n",
      "fullSet, iter: 2 i:97, pairs changed 0\n",
      "fullSet, iter: 2 i:98, pairs changed 0\n",
      "fullSet, iter: 2 i:99, pairs changed 0\n",
      "iteration number: 3\n",
      "[1, -1, -1, 1, -1, 1, 1, -1, 1, -1, -1, -1, 1, 1, 1, -1, -1, 1, -1, -1]\n"
     ]
    }
   ],
   "source": [
    "#Main Method execution \n",
    "#Load in dataset - assigns to two lists\n",
    "#dataMatIn \n",
    "#classLabels\n",
    "dataMatIn, classLabels = loadDataSet('data.txt')\n",
    "\n",
    "#Initialise class - my_model\n",
    "my_model = svm_basic()\n",
    "\n",
    "#Fit data \n",
    "my_model.fit(dataMatIn, classLabels)\n",
    "\n",
    "#Splitting data into ratio 1:4 - test_size = 20%\n",
    "#Predict data on test set: test_set == X_test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(dataMatIn, classLabels, test_size=0.2, random_state=121)\n",
    "test_set = np.array(X_test)\n",
    "result = my_model.predict(test_set.T)\n",
    "\n",
    "#Declare classification list for test results\n",
    "classification = []\n",
    "for a in np.nditer(result):\n",
    "    if a >= 0 :\n",
    "        classification.append(1)\n",
    "    else :\n",
    "        classification.append(-1)\n",
    "print(classification)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          x1        x2  Class\n",
      "0   4.846514  1.772123      1\n",
      "1   0.933640  5.224675     -1\n",
      "2   0.874154  5.254460     -1\n",
      "3   4.455876 -0.309145      1\n",
      "4   1.495002  3.398053     -1\n",
      "5   3.970198  1.635354      1\n",
      "6   5.266461  0.934631      1\n",
      "7   0.786590  5.769403     -1\n",
      "8   5.388044  1.702283      1\n",
      "9   1.844324  4.208922     -1\n",
      "10  1.933917  5.098318     -1\n",
      "11 -0.838550  4.068960     -1\n",
      "12  3.039194 -0.872500      1\n",
      "13  5.858049  0.554408      1\n",
      "14  3.788795 -0.856824      1\n",
      "15  0.370945  3.490625     -1\n",
      "16  1.800717  4.719398     -1\n",
      "17  5.905040  0.098958      1\n",
      "18 -0.019964  3.623664     -1\n",
      "19  0.461192  3.379534     -1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x1c2085a0f0>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAFgCAYAAACsSp6OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c2085a860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Placing test_data into DataFrame\n",
    "#Placing classification data into DataFrame\n",
    "testDF = pd.DataFrame(X_test, columns= ['x1','x2'])\n",
    "classDF = pd.DataFrame(classification, columns =['Class'])\n",
    "\n",
    "#Combining DataFrames into one - finalResult\n",
    "frames = [testDF, classDF]\n",
    "finalResult = pd.concat(frames, axis = 1)\n",
    "print(finalResult)\n",
    "\n",
    "#Plot new data on finalResult\n",
    "sns.lmplot('x1', 'x2', data=finalResult, ci = None, hue=\"Class\", fit_reg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
